# ğŸ“Š Real-Time Job Market Analytics

A Full-stack, cloud-deployed application that scrapes live jobs postings on demand, processes then through an ETL pipeline, and visualize real-time job market trends using interactice dashboards. 
---

## ğŸš€ Project Overview 

- Real-Time Job Market Analytics enables users to search for jobs by roles and location , dynamically triggers web scraping, and analyze hiring trends such as top companies, location, and in-demand skills.
- The system follows a decoupled, production-grade architecture with separate frontend, backend, scraping pipeline and cloud database.

## ğŸ—ï¸ System Architecture

```text
Frontend (Netlify)
   |
   |  REST API Calls
   v
Backend API (FastAPI â€“ Render)
   |
   |  Background Task
   v
Web Scraper (Playwright)
   |
   v
Transform Layer (Skill Extraction + Deduplication)
   |
   v
Database (TiDB Cloud â€“ MySQL Compatible)

```
## ğŸ§© Key Features
- ğŸ” User-Driven job search (role & city)
- ğŸŒ On-demand web scraping using playwight
- ğŸ”„ ETL pipeline (Extract -> Transform -> Load)
- ğŸ§  Skill extraction fron job titles
- ğŸ“Š Interactive analytical dashboards (Chart.js)
- â˜ï¸ Cloud-native deployment
- ğŸ§± Decoupled frontend & backend

## ğŸ› ï¸ Tech Stack
**Backend**
- FastAPI
- Python
- Playwright (web scraping)
- MySQL (Connector)
- 
**Database**
- TiDB Cloud (serverless MySQL - compatible database)
- 
**Frontend**
- HTML
- CSS
- JavaScript
- Chart.js
  
**Deployment**
- Render -> Backend API
- Netlify -> Frondend
- GitHub -> Version control

## ğŸ“‚ Project Structure
```text
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py              # FastAPI entry point
â”‚   â”œâ”€â”€ analytics.py        # SQL-based analytics logic
â”‚   â”œâ”€â”€ db.py               # Database connection & inserts
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ extract/
â”‚   â”‚   â””â”€â”€ scraper.py      # Playwright scraper
â”‚   â”œâ”€â”€ transform/
â”‚   â”‚   â””â”€â”€ clean.py        # Skill extraction & cleaning
â”‚   â””â”€â”€ run_pipeline.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ css/
â”‚       â””â”€â”€ js/
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```

## ğŸ”„ Data Flow (ETL)
1. Extract
  - Scrape job listings from Indeed using Playwright.
  - Triggered only when the user submits a search.
  
2. Transform
  - Clean text data
  - Remove duplicates
  - Extract technical skills using keyword matching

3. Load
  - Store structured data in TidDB Cloud
  - Optimized for analytics queries

# ğŸ”Œ API Endpoints

Health Check
```text
GET /
```
Trigger Scraping
```text
POST /scrape
```
Payload
```text
{
  "role": "python developer",
  "city": "bangalore"
}
```
Analytics
```text
GET /analytics/locations
GET /analytics/companies
GET /analytics/skills
```
Paginated Job Listings
```text
GET /jobs?page=1&limit=10&role=python&location=india
```
## ğŸŒ Live Deployment
- Backend API: Render
- Fronend Dashboard : Netlify
- Database : TiDB cloud
The frontend communicates with the backend via REST APIs, following a fully decoupled deployment model.

## ğŸ” Design Decisions
* Scraping runs only on demand, not continuously
* Background tacks prevent blocking API response
* No scraping logic runs at server startup
* Cloud-safe database connections with environment variables
* CORS enabled for cross-origin frontend access

## ğŸ§ª How to Run Locally
**Backend**
```text
pip install -r requirements.txt
```
```text
uvicorn backend.app:app --reload
```
**Frontend**

Open frontend/index.html directly in the browser
(or serve with a simple static server)

## ğŸ“ˆ Future Enhancements

- Job description scraping
- Skill frequency trends over time
- Authentication for scrape endpoint
- Rate limiting & retry logic
- Dockerized deployment
- Support for multiple job boards

## ğŸ§¾ Resume Highlight

Built a real-time job market analytics platform using FASTAPI, Playwright, and TiDB Cloud with an on-demand ETL pipeline and interative frontend dashboard.
Deployed a decoupled cloud architecture with backend services on Render and Frontend on Netlify.

## ğŸ§  Final Note
This project demonstrate backend engineering, data engineering, cloud deployment and frontend integration
in a single system -- designed and implemented ene-to-end.

